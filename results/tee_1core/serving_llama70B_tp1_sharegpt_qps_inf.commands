{
  "server_command": "taskset -c 0 python3       -m vllm.entrypoints.openai.api_server       --model meta-llama/Meta-Llama-3.1-70B-Instruct --tensor-parallel-size 1 --quantization bitsandbytes --load-format bitsandbytes --swap-space 16 --disable-log-stats  --disable-log-requests ",
  "client_command": "python3 benchmark_serving.py         --save-result         --result-dir results/         --result-filename serving_llama70B_tp1_sharegpt_qps_inf.json         --request-rate inf         --model meta-llama/Meta-Llama-3.1-70B-Instruct --backend vllm --dataset-name sharegpt --dataset-path ./ShareGPT_V3_unfiltered_cleaned_split.json --num-prompts 1000",
  "gpu_type": "H200"
}
